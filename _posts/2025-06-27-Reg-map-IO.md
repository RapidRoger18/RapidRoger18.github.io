---
layout: post
title:  "I/O Interfacing: How about Register Mapping"
author: Atharva
categories: [ GSOC ]
tags: [Updates]
image: ../assets/images/BeagleV-Fire.png
description: "Exploring register-mapped register I/O for BeagleV-Fire, balancing speed optimizations with latency challenges"
featured: false
hidden: false
---
During my recent work on memory-mapped I/O (MMIO) testing, I encountered significant challenges that led me to explore alternative solutions. One idea that emerged was to implement register-mapped I/O, albeit in a modified form from traditional methods. This approach involved using memory-mapped registers where each bit represents an I/O pin, aligning well with the existing CAPE module on the BeagleV-Fire platform.

To execute this strategy, extensive discussions with my mentors highlighted that while this method may not be the fastest, other approaches such as custom instruction sets for I/O operations would overly complicate the project beyond the scope of GSOC.

I proceeded to map I/O to registers using Verilog in my IO Controller, integrating these addresses as wrappers to the main CPU. This method offered several advantages:
- Single Cycle Access: All I/O operations can be accessed within a single cycle.
- Reduced Latency: Coupling I/O pins via registers decreased latency significantly.

In practical terms, the C code retained its simplicity:

```C:
#define GPIO_INPUT   (*(volatile uint32_t *) 0x03000000)
#define GPIO_OE      (*(volatile uint32_t *) 0x03000004)
#define GPIO_OUTPUT  (*(volatile uint32_t *) 0x03000008)
```
Given the 32-bit data width of the processor, uint32_t was used as the data type, with each address spaced 4 units apart to address individual bytes of data. This structure aligned well with how I/Os are mapped within the BeagleV-Fire Gateware, streamlining accessibility.

Despite these advancements, challenges remained:
- Speed Dependency: The access speed still hinges on the processor's memory operation capabilities.
- Latency Concerns: Achieved latencies were not as minimal as those of conventional PRU subsystems.

Considering exhaustive testing over the past weeks, neither method delivered optimal results. However, recognizing the potential for faster bulk operations, we opted to utilize this approach temporarily while continuing our search for refinements.

Reflecting on this experience, the importance of consistent mentor communication emerged as crucial. Keeping mentors updated on progress—even when not prompted—proved invaluable. Additionally, engaging with the broader community proved instrumental, with community input often providing critical project insights. Embracing a proactive mindset and seeking guidance from those more knowledgeable fostered significant project growth.